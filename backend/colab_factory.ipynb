{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè≠ LLaMA Factory (Web UI Fine-Tuning) + GGUF Export\n",
                "‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏î! ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ô‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î\n",
                "(‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ + ThaiLLM-8B)\n",
                "\n",
                "### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:\n",
                "1. ‡∏Å‡∏î‡∏£‡∏±‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö\n",
                "2. ‡∏£‡∏≠‡∏à‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå `Running on public URL: https://xxxx.gradio.live`\n",
                "3. ‡∏Å‡∏î‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ Training\n",
                "\n",
                "### ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å: ‡∏ï‡∏≠‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Name)\n",
                "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (ThaiLLM 8B - Qwen 2.5) ‡πÉ‡∏´‡πâ‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á **Model Name** ‡∏Ñ‡∏£‡∏±‡∏ö:\n",
                "üëâ `ThaiLLM/ThaiLLM-8B`\n",
                "\n",
                "### ‡∏ß‡∏¥‡∏ò‡∏µ Export ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏≥‡∏Å‡∏•‡∏±‡∏ö‡∏ö‡πâ‡∏≤‡∏ô üè†:\n",
                "1. ‡∏ù‡∏∂‡∏Å (Train) ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß -> ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö **\"Export\"** (‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô)\n",
                "2. ‡∏ï‡∏£‡∏á **\"Export Format\"** ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å **`GGUF`** (‡∏´‡∏£‡∏∑‡∏≠ `llama.cpp`)\n",
                "3. ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° `Export` ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 0. Check GPU\n",
                "import torch\n",
                "try:\n",
                "    assert torch.cuda.is_available()\n",
                "    print(\"‚úÖ GPU Detected:\", torch.cuda.get_device_name(0))\n",
                "except:\n",
                "    print(\"‚ùå No GPU detected! Go to Runtime > Change runtime type > T4 GPU\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install LLaMA Factory & Unsloth\n",
                "print(\"‚è≥ Installing LLaMA Factory (Approx 3-5 mins)...\")\n",
                "import os\n",
                "%cd /content\n",
                "if not os.path.exists(\"LLaMA-Factory\"):\n",
                "    !git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
                "\n",
                "%cd LLaMA-Factory\n",
                "!pip install -q -e .[metrics,bitsandbytes,lmtuner]\n",
                "!pip install -q unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\n",
                "\n",
                "# Install dependency for GGUF Export\n",
                "!pip install -q --no-deps -U \"llama-cpp-python\"\n",
                "\n",
                "print(\"‚úÖ Installed Successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Start Web UI\n",
                "import os\n",
                "os.environ[\"GRADIO_SHARE\"] = \"1\"\n",
                "\n",
                "print(\"üöÄ Starting Web UI...\")\n",
                "print(\"----------------------------------------------------------------\")\n",
                "print(\"üî• ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°! ‡∏ä‡πà‡∏≠‡∏á Model Name ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö (‡∏Å‡πä‡∏≠‡∏õ‡πÑ‡∏õ‡∏ß‡∏≤‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢):\")\n",
                "print(\"üëâ ThaiLLM/ThaiLLM-8B\")\n",
                "print(\"----------------------------------------------------------------\")\n",
                "print(\"üëâ ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà... ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏´‡πá‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå 'Running on public URL' ‡πÉ‡∏´‡πâ‡∏Å‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!\")\n",
                "\n",
                "!llamafactory-cli webui"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}