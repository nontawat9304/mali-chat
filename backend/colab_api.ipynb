{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ AInote Remote Brain (Colab GPU) - Drive Mode\n",
                "‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ: ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå GGUF ‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô‡πÑ‡∏õ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Google Drive ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies (GPU Enabled)\n",
                "!CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python\n",
                "!pip install pyngrok uvicorn fastapi sse-starlette pydantic-settings starlette-context"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Mount Google Drive (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏î‡∏£‡∏ü‡πå)\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "\n",
                "# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ ---\n",
                "# ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏∏: ThaiLLM-8B-Instruct.Q8_0.gguf (‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Model)\n",
                "DRIVE_PATH = \"/content/drive/MyDrive/Model/ThaiLLM-8B-Instruct.Q8_0.gguf\" \n",
                "\n",
                "if os.path.exists(DRIVE_PATH):\n",
                "    print(f\"‚úÖ ‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß! ({DRIVE_PATH})\")\n",
                "    MODEL_PATH = DRIVE_PATH\n",
                "else:\n",
                "    print(f\"‚ùå ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ó‡∏µ‡πà: {DRIVE_PATH}\")\n",
                "    print(\"üëâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .gguf ‡πÑ‡∏õ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà Google Drive ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Model ‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Setup Ngrok & Run Server\n",
                "from pyngrok import ngrok\n",
                "import getpass\n",
                "\n",
                "# --- ‡πÉ‡∏™‡πà Token ‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (Interactive) ---\n",
                "# ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ü‡∏£‡∏µ‡∏ó‡∏µ‡πà https://dashboard.ngrok.com/get-started/your-authtoken\n",
                "print(\"üîë ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á Ngrok Token ‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡∏Å‡∏î Paste ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Enter):\")\n",
                "NGROK_TOKEN = getpass.getpass(\"Insert Ngrok Token: \")\n",
                "\n",
                "if not NGROK_TOKEN or len(NGROK_TOKEN) < 10:\n",
                "    print(\"‚ùå ‡∏ó‡πà‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏™‡πà Token ‡∏Ñ‡∏£‡∏±‡∏ö!\")\n",
                "else:\n",
                "    ngrok.set_auth_token(NGROK_TOKEN)\n",
                "    \n",
                "    # Close old tunnels\n",
                "    ngrok.kill()\n",
                "    \n",
                "    # Open Tunnel to port 8000\n",
                "    public_url = ngrok.connect(8000).public_url\n",
                "    print(f\"\\nüöÄ COPY ‡∏•‡∏¥‡πâ‡∏á‡∏Å‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÉ‡∏™‡πà‡πÉ‡∏ô .env ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏£‡∏±‡∏ö: {public_url}/v1\\n\")\n",
                "    \n",
                "    # Run Server (‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Drive ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)\n",
                "    if 'MODEL_PATH' in locals() and os.path.exists(MODEL_PATH):\n",
                "        # ‡πÄ‡∏û‡∏¥‡πà‡∏° --n_ctx 8192 (‡∏Ç‡∏¢‡∏≤‡∏¢‡∏™‡∏°‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 8192 ‡∏Ñ‡∏≥) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ‡πÑ‡∏î‡πâ\n",
                "        !python -m llama_cpp.server --model \"$MODEL_PATH\" --n_gpu_layers -1 --n_ctx 8192 --host 0.0.0.0 --port 8000\n",
                "    else:\n",
                "        print(\"‚ùå ‡∏£‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠\")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}